{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of LDA and LSA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation (LDA) and Latent Semantic Analysis (LSA) are both statistical techniques used for topic modeling in natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA is a generative probabilistic model that assumes documents are mixtures of topics and that each topic is characterized by a distribution of words. It is particularly effective for discovering hidden thematic structures in large collections of text, making it useful for applications such as document classification, recommendation systems, and content summarization. LDA generates interpretable topics, allowing users to understand the themes present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA, on the other hand, is based on singular value decomposition (SVD) and reduces the dimensionality of the term-document matrix. It identifies patterns in the relationships between terms and documents, capturing the underlying semantic structure. LSA is commonly used for information retrieval, document clustering, and improving search results by understanding the context of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to perform LDA\n",
    "def perform_lda(documents, num_topics=5):\n",
    "    \"\"\"\n",
    "    Perform Latent Dirichlet Allocation (LDA) on the provided documents.\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: List of lemmatized documents.\n",
    "    - num_topics: Number of topics to extract.\n",
    "\n",
    "    Returns:\n",
    "    - lda_model: Trained LDA model.\n",
    "    - corpus: Corpus for LDA.\n",
    "    - dictionary: Dictionary for LDA.\n",
    "    \"\"\"\n",
    "    # Prepare the documents for LDA\n",
    "    texts = [doc.split() for doc in documents]\n",
    "    \n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "    \n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "# Function to perform LSA\n",
    "def perform_lsa(documents, num_topics=5):\n",
    "    \"\"\"\n",
    "    Perform Latent Semantic Analysis (LSA) on the provided documents.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: List of lemmatized documents.\n",
    "    - num_topics: Number of topics to extract.\n",
    "\n",
    "    Returns:\n",
    "    - lsa_model: Trained LSA model.\n",
    "    - svd: SVD transformation.\n",
    "    \"\"\"\n",
    "    # Convert documents to a document-term matrix\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Perform SVD\n",
    "    svd = TruncatedSVD(n_components=num_topics)\n",
    "    lsa_model = svd.fit_transform(X)\n",
    "    \n",
    "    return lsa_model, svd, vectorizer\n",
    "\n",
    "# Example usage\n",
    "def analyze_topics(global_attributes_dict):\n",
    "    \"\"\"\n",
    "    Analyze topics using LDA and LSA and display results.\n",
    "\n",
    "    Parameters:\n",
    "    - global_attributes_dict: Global attributes dictionary for analysis.\n",
    "    \"\"\"\n",
    "    # Prepare a list of lemmatized chapter texts for analysis\n",
    "    documents = [' '.join(attrs) for attrs in global_attributes_dict.values() if attrs]\n",
    "\n",
    "    # Perform LDA\n",
    "    lda_model, corpus, dictionary = perform_lda(documents, num_topics=5)\n",
    "    \n",
    "    # Display the topics found by LDA\n",
    "    print(\"LDA Topics:\")\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Topic {idx + 1}: {topic}\")\n",
    "\n",
    "    # Perform LSA\n",
    "    lsa_model, svd, vectorizer = perform_lsa(documents, num_topics=5)\n",
    "\n",
    "    # Display the topics found by LSA\n",
    "    print(\"\\nLSA Topics:\")\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    for i, topic in enumerate(svd.components_):\n",
    "        print(f\"Topic {i + 1}: \", end=\"\")\n",
    "        print(\" + \".join([f\"{terms[j]} * {topic[j]:.4f}\" for j in topic.argsort()[-3:]]))\n",
    "\n",
    "# Call the analyze_topics function with the global attributes dictionary\n",
    "analyze_topics(global_attributes_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Compare LDA and LSA:\n",
    "1) Calculate Coherence Scores: We'll compute coherence scores for both LDA and LSA topics.\n",
    "2) Visualize Results: Finally, we'll visualize the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare LDA and LSA topic models\n",
    "def compare_lda_lsa(global_attributes_dict, num_topics=5):\n",
    "    documents = [' '.join(attrs) for attrs in global_attributes_dict.values() if attrs]\n",
    "\n",
    " # Visualization: Plot LDA and LSA side by side for comparison\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot LDA topics\n",
    "    ax[0].barh(range(len(lda_topics)), [len(topic.split()) for topic in lda_topics], color='skyblue')\n",
    "    ax[0].set_title('LDA Topic Word Count')\n",
    "    ax[0].set_yticks(range(len(lda_topics)))\n",
    "    ax[0].set_yticklabels([f\"Topic {i+1}\" for i in range(len(lda_topics))])\n",
    "    \n",
    "    # Plot LSA topics\n",
    "    ax[1].barh(range(len(lsa_topics)), [len(topic.split()) for topic in lsa_topics], color='lightcoral')\n",
    "    ax[1].set_title('LSA Topic Word Count')\n",
    "    ax[1].set_yticks(range(len(lsa_topics)))\n",
    "    ax[1].set_yticklabels([f\"Topic {i+1}\" for i in range(len(lsa_topics))])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the global attributes dictionary\n",
    "compare_lda_lsa(global_attributes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LDA and LSA add practical value by providing distinct perspectives on the dataset's underlying structure, and their effects are visible in the graph.\n",
    "\n",
    "LDA focuses on discovering probabilistic topic distributions within the dataset. This means that it extracts topics that represent well-separated, interpretable groups of words. In the graph, this adds value by clustering terms into clearly defined topics, making it easier to differentiate between various themes in the documents. LDA helps identify dominant, well-structured topics that are coherent and relevant to specific document sections.\n",
    "\n",
    "LSA, on the other hand, leverages matrix factorization (SVD) to find latent patterns and relationships between words that might not be immediately apparent. This adds value by highlighting subtle, semantic relationships across documents, showing how certain terms co-occur even if they do not frequently appear together. In the graph, LSA can provide insights into hidden connections between terms, revealing deeper structures in the text that go beyond simple topic modeling.\n",
    "\n",
    "Both methods enrich the analysis in complementary ways: LDA offers clear, interpretable topics, while LSA uncovers broader patterns of term association, helping to capture a more comprehensive picture of the dataset's semantic structure."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of LDA and LSA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to perform LDA\n",
    "def perform_lda(documents, num_topics=5):\n",
    "    \"\"\"\n",
    "    Perform Latent Dirichlet Allocation (LDA) on the provided documents.\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: List of lemmatized documents.\n",
    "    - num_topics: Number of topics to extract.\n",
    "\n",
    "    Returns:\n",
    "    - lda_model: Trained LDA model.\n",
    "    - corpus: Corpus for LDA.\n",
    "    - dictionary: Dictionary for LDA.\n",
    "    \"\"\"\n",
    "    # Prepare the documents for LDA\n",
    "    texts = [doc.split() for doc in documents]\n",
    "    \n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "    \n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "# Function to perform LSA\n",
    "def perform_lsa(documents, num_topics=5):\n",
    "    \"\"\"\n",
    "    Perform Latent Semantic Analysis (LSA) on the provided documents.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: List of lemmatized documents.\n",
    "    - num_topics: Number of topics to extract.\n",
    "\n",
    "    Returns:\n",
    "    - lsa_model: Trained LSA model.\n",
    "    - svd: SVD transformation.\n",
    "    \"\"\"\n",
    "    # Convert documents to a document-term matrix\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Perform SVD\n",
    "    svd = TruncatedSVD(n_components=num_topics)\n",
    "    lsa_model = svd.fit_transform(X)\n",
    "    \n",
    "    return lsa_model, svd, vectorizer\n",
    "\n",
    "# Example usage\n",
    "def analyze_topics(global_attributes_dict):\n",
    "    \"\"\"\n",
    "    Analyze topics using LDA and LSA and display results.\n",
    "\n",
    "    Parameters:\n",
    "    - global_attributes_dict: Global attributes dictionary for analysis.\n",
    "    \"\"\"\n",
    "    # Prepare a list of lemmatized chapter texts for analysis\n",
    "    documents = [' '.join(attrs) for attrs in global_attributes_dict.values() if attrs]\n",
    "\n",
    "    # Perform LDA\n",
    "    lda_model, corpus, dictionary = perform_lda(documents, num_topics=5)\n",
    "    \n",
    "    # Display the topics found by LDA\n",
    "    print(\"LDA Topics:\")\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Topic {idx + 1}: {topic}\")\n",
    "\n",
    "    # Perform LSA\n",
    "    lsa_model, svd, vectorizer = perform_lsa(documents, num_topics=5)\n",
    "\n",
    "    # Display the topics found by LSA\n",
    "    print(\"\\nLSA Topics:\")\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    for i, topic in enumerate(svd.components_):\n",
    "        print(f\"Topic {i + 1}: \", end=\"\")\n",
    "        print(\" + \".join([f\"{terms[j]} * {topic[j]:.4f}\" for j in topic.argsort()[-3:]]))\n",
    "\n",
    "# Call the analyze_topics function with the global attributes dictionary\n",
    "analyze_topics(global_attributes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    \"Machine learning is great for data analysis.\",\n",
    "    \"Natural language processing helps in understanding human languages.\",\n",
    "    \"Deep learning is a subset of machine learning.\",\n",
    "    \"Data science combines statistics and machine learning.\",\n",
    "    \"Artificial intelligence is the future of technology.\"\n",
    "]\n",
    "\n",
    "# Preprocessing the text\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to a bag-of-words format for LDA\n",
    "corpus = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "# LDA Model\n",
    "lda_model = LdaModel(corpus=dictionary.doc2bow(doc) for doc in corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "lda_coherence_model = CoherenceModel(model=lda_model, texts=corpus, dictionary=dictionary, coherence='c_v')\n",
    "lda_coherence_score = lda_coherence_model.get_coherence()\n",
    "\n",
    "# LSA Model\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "lsa_topic_matrix = svd.fit_transform(X)\n",
    "lsa_coherence_score = np.mean([np.corrcoef(lsa_topic_matrix[i], lsa_topic_matrix[j])[0, 1] for i in range(lsa_topic_matrix.shape[0]) for j in range(i+1, lsa_topic_matrix.shape[0])])\n",
    "\n",
    "# Display results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['LDA', 'LSA'],\n",
    "    'Coherence Score': [lda_coherence_score, lsa_coherence_score]\n",
    "})\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Coherence Score', data=results)\n",
    "plt.title('Coherence Scores Comparison: LDA vs. LSA')\n",
    "plt.ylim(0, max(results['Coherence Score']) + 0.1)\n",
    "plt.show()\n",
    "\n",
    "print(f'LDA Coherence Score: {lda_coherence_score:.4f}')\n",
    "print(f'LSA Coherence Score: {lsa_coherence_score:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
